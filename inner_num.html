<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Sameer Shaik Portfolio</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: iPortfolio - v3.1.0
  * Template URL: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <i class="bi bi-list mobile-nav-toggle d-xl-none"></i>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="propic.jpg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Sameer Shaik</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://www.linkedin.com/in/sameershaik65/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
          <a href="https://www.facebook.com/profile.php?id=100004454386197" class="facebook"><i class="bx bxl-facebook"></i></a>
          <a href="https://www.instagram.com/sameer_carpediem/" class="instagram"><i class="bx bxl-instagram"></i></a>
          <a href="https://accounts.google.com/ServiceLogin/identifier?service=mail&passive=true&rm=false&continue=https%3A%2F%2Fmail.google.com%2Fmail%2F&ss=1&scc=1&ltmpl=default&ltmplcache=2&emr=1&osid=1&flowName=GlifWebSignIn&flowEntry=ServiceLogin" class="gmail"><i class="bx bxl-google"></i></a>
		  <a href="https://twitter.com/sameers17324444" class="twitter"><i class="bx bxl-twitter"></i></a>
          
        </div>
      </div>

      <nav id="navbar" class="nav-menu navbar">
        <ul>
          <li><a href="#hero" class="nav-link scrollto active"><i class="bx bx-home"></i> <span>Home</span></a></li>
          <li><a href="#about" class="nav-link scrollto"><i class="bx bx-user"></i> <span>About</span></a></li>
          <li><a href="#resume" class="nav-link scrollto"><i class="bx bx-file-blank"></i> <span>Resume</span></a></li>
          <li><a href="#portfolio" class="nav-link scrollto"><i class="bx bx-book-content"></i> <span>Portfolio</span></a></li>
          <li><a href="#contact" class="nav-link scrollto"><i class="bx bx-server"></i> <span>contact</span></a></li>
          <li><a href="#contact" class="nav-link scrollto"><i class="bx bx-envelope"></i> <span>Contact</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
         <h3 style="background-color:LightBlue;"> Fundamentals of Numpy & PyTorch</h3>
            <li><a href="index.html">Home<</a></li>
        
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->

    <section class="inner-page">
      <div class="container">
        <p>
          NumPy is one of the Python libraries, that supports multi-dimensional, substantial arrays as well as matrices. It also supports a large collection of mathematical functions to operate on these arrays. NumPy provides a strong base for many other data science and data visualization libraries.
        </p>
		<p>PyTorch is a library for Python programs that facilitates building deep learning projects.In a simple sentence, think about Numpy, but with strong GPU acceleration. Better yet, PyTorch supports dynamic computation graphs that allow you to change how the network behaves on the fly</p>
      </div>
	  <div>
	  
	  </div>
	  <div>
	  
<link type="application/atom+xml" rel="alternate" href="https://rickwierenga.com/feed.xml" title="Rick Wierenga" />
<link href="/assets/stylesheets/main.css" rel="stylesheet">
<meta name="description" content="A blog about whatever interests me.">
<meta name="viewport" content="width=device-width">

<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:h3" content="Numpy vs PyTorch for Linear Algebra" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Numpy is one of the most popular linear algebra libraries right now. There’s also PyTorch - an open source deep learning framework developed by Facebook Research. While the latter is best known for its machine learning capabilities, it can also be used for linear algebra, just like Numpy." />
<meta property="og:description" content="Numpy is one of the most popular linear algebra libraries right now. There’s also PyTorch - an open source deep learning framework developed by Facebook Research. While the latter is best known for its machine learning capabilities, it can also be used for linear algebra, just like Numpy." />
<link rel="canonical" href="https://rickwierenga.com/blog/machine%20learning/numpy-vs-pytorch-linalg.html" />
<meta property="og:url" content="https://rickwierenga.com/blog/machine%20learning/numpy-vs-pytorch-linalg.html" />
<meta property="og:site_name" content="Rick Wierenga" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-08-08T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Numpy vs PyTorch for Linear Algebra" />
<meta name="twitter:site" content="@rickwierenga" />
<script type="application/ld+json">
{"datePublished":"2019-08-08T00:00:00+00:00","description":"Numpy is one of the most popular linear algebra libraries right now. There’s also PyTorch - an open source deep learning framework developed by Facebook Research. While the latter is best known for its machine learning capabilities, it can also be used for linear algebra, just like Numpy.","url":"https://rickwierenga.com/blog/machine%20learning/numpy-vs-pytorch-linalg.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://rickwierenga.com/blog/machine%20learning/numpy-vs-pytorch-linalg.html"},"headline":"Numpy vs PyTorch for Linear Algebra","dateModified":"2019-08-08T00:00:00+00:00","@context":"https://schema.org"}</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143822145-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-143822145-1');
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
  }
});
</script>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_SVG"></script>
<link rel="stylesheet" href="/assets/stylesheets/post.css">
</head>
<body>
</ul>
</nav>
</div>
</header>
<div id="content">
<div id="content-inside">
<div class="container tight">
<article class="post-content">
<header>
<div class="titles">
<h1>Numpy vs PyTorch for Linear Algebra</h1>
<h2></h2>
</div>
</header>
<p>Numpy is one of the most popular linear algebra libraries right now. There’s also PyTorch - an open source deep learning framework developed by Facebook Research. While the latter is best known for its machine learning capabilities, it can also be used for linear algebra, just like Numpy.</p>
<p>The most important difference between the two frameworks is naming. Numpy calls tensors (high dimensional matrices or vectors) arrays while in PyTorch there’s just called tensors. Everything else is quite similar.</p>
<h2 id="why-pytorch">Why PyTorch?</h2>
<p>Even if you already know Numpy, there are still a couple of reasons to switch to PyTorch for tensor computation. The main reason is the GPU acceleration. As you’ll see, using a GPU with PyTorch is super easy and super fast. If you do large computations, this is beneficial because it speeds things up a lot.</p>
<p>The other reason is the integration with other parts of the PyTorch framework. Most people use linear algebra for some kind of machine learning nowadays. In this case, using PyTorch is probably a better choice because the data can be used with the rest of the framework.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
</code></pre></div></div>
<h2 id="why-numpy">Why Numpy?</h2>
<p>Numpy is the most commonly used computing framework for linear algebra. A good use case of Numpy is quick experimentation and small projects because Numpy is a light weight framework compared to PyTorch.</p>
<p>Moreover, PyTorch lacks a few advanced features as you’ll read below so it’s strongly recommended to use numpy in those cases.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>
<h2 id="using-both">Using Both</h2>
<p>Fortunately, using one framework doesn’t exclude the other. You can get the best of both worlds by converting between Numpy arrays and PyTorch tensors.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Numpy -&gt; PyTorch
</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np_array</span><span class="p">)</span>

<span class="c1"># PyTorch -&gt; Numpy
</span><span class="n">ndarray</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span>
</code></pre></div></div>
<h2 id="new-tensors">New tensors</h2>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">zeros</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ones</span>   <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">random</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">zeros</span>  <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ones</span>   <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">random</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>
<h2 id="basic-linear-algebra">Basic Linear Algebra</h2>
<h3 id="indexing">Indexing</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Index item
</span><span class="n">array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># returns a float
</span>
<span class="c1"># Index row
</span><span class="n">array</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># returns an array
</span></code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Index item
</span><span class="n">torch</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># returns a tensor
</span>
<span class="c1"># Index row
</span><span class="n">torch</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># returns a tensor
</span></code></pre></div></div>
<h3 id="addition--subtraction">Addition &amp; subtraction</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">array</span> <span class="o">+</span> <span class="n">array2</span>
<span class="n">array</span> <span class="o">-</span> <span class="n">array2</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">+</span> <span class="n">tensor2</span>
<span class="n">tensor</span> <span class="o">-</span> <span class="n">tensor2</span>
</code></pre></div></div>
<h3 id="element-wise-multiplication">(Element wise) multiplication</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Element wise
</span><span class="n">array</span> <span class="o">*</span> <span class="n">array</span>

<span class="c1"># Matrix multiplication
</span><span class="n">array</span> <span class="o">@</span> <span class="n">array</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Element wise
</span><span class="n">tensor</span> <span class="o">*</span> <span class="n">tensor</span>

<span class="c1"># Matrix multiplication
</span><span class="n">tensor</span> <span class="o">@</span> <span class="n">tensor</span>
</code></pre></div></div>
<h3 id="shape-and-dimensions">Shape and dimensions</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shap</span>    <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="n">shape</span>
<span class="n">num_dim</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="n">ndim</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shape</span>   <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">shape</span>
<span class="n">shape</span>   <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="c1"># equal to `.shape`
</span><span class="n">num_dim</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">dim</span><span class="p">()</span>
</code></pre></div></div>
<h3 id="reshaping">Reshaping</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_array</span> <span class="o">=</span> <span class="n">array</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
<h3 id="determinant">Determinant</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">det</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># not natively supported
</span></code></pre></div></div>
<h3 id="inverse-and-moore-pensore-inverse">Inverse and Moore-Pensore inverse</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inverse
</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>

<span class="c1"># Moore Pensore inverse
</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Inverse
</span><span class="n">tensor</span><span class="p">.</span><span class="n">inverse</span><span class="p">()</span>

<span class="c1"># Moore Pensore inverse
</span><span class="n">tensor</span><span class="p">.</span><span class="n">pinverse</span><span class="p">()</span>
</code></pre></div></div>
<h3 id="summeanstd">Sum/mean/std</h3>
<p>These functions return floating point numbers in Numpy where PyTorch returns 1 by 1 tensors.</p>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sum
</span><span class="n">array</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>

<span class="c1"># Mean
</span><span class="n">array</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Standard Deviation
</span><span class="n">array</span><span class="p">.</span><span class="n">std</span><span class="p">()</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Sum
</span><span class="n">tensor</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>

<span class="c1"># Mean
</span><span class="n">tensor</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Standard Deviation
</span><span class="n">tensor</span><span class="p">.</span><span class="n">std</span><span class="p">()</span>
</code></pre></div></div>
<h3 id="transpose">Transpose</h3>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">array</span><span class="p">.</span><span class="n">T</span>
<span class="n">array</span><span class="p">.</span><span class="n">transpose</span><span class="p">()</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span><span class="p">.</span><span class="n">t</span><span class="p">()</span>
</code></pre></div></div>
<h2 id="saving-to-disk">Saving to disk</h2>
<p>Saving results to disk is a huge time server. Here’s how you’d do it in Numpy or PyTorch.</p>
<p>Numpy:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">'file.npy'</span><span class="p">,</span> <span class="n">array</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'file.npy'</span><span class="p">)</span>
</code></pre></div></div>
<p>PyTorch:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="s">'file'</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'file'</span><span class="p">)</span>
</code></pre></div></div>
<h2 id="using-the-gpu">Using the GPU</h2>
<p>This is where PyTorch really shines. By copying an array to the GPU memory, there’s a huge potential for performance improvements due to heavy parallelization. Note that PyTorch uses CUDA under the hood so only NVIDIA GPUs are supported.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># put the tensor in GPU memory
</span><span class="n">gpu_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="n">gpu</span><span class="p">()</span>
</code></pre></div></div>
<p>In Google Colab I got a 20.9 time speed up in multiplying a 10000 by 10000 matrix by a scaler when using the GPU.</p>
<p>If you do an operation on two arrays, both must be either on the CPU or GPU.</p>
<h2 id="further-reading">Further reading</h2>
<ul>
<li><a href="https://pytorch.org/docs/stable/tensors.html">PyTorch Tensor Documentation</a></li>
<li><a href="https://docs.scipy.org/doc/numpy/reference/arrays.html">Numpy Array Documentation</a></li>
</ul>
	  </div>
		 
    </section>

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
        &copy; Copyright <strong><span>iPortfolio</span></strong>
      </div>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/ -->
        Designed by <a href="https://www.linkedin.com/in/sameershaik65/">Sameer Shaik</a>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>